{
  "hash": "b3a145a920b25c3d74f7a22c34171b45",
  "result": {
    "markdown": "---\ntitle: \"Instrumental Variables\"\n---\n\n\n# Assignment \n\n*  Imagine the following situation: you have developed an app and you are already having an active user base. Of course, some users are more active than other users. Also, users might use the app for different purposes. In general, user behavior likely depends on a lot of unobserved characteristics.\n*  Obviously, your goal is to keep users as long as possible on the app to maximize your ad revenues. To do that, you want to introduce a new feature and see how it affects time spent on the app. Simply comparing users who use the newly introduced feature to users who don’t would result in a biased estimate due to the unobserved confounders regarding their activity and willingness to use a new feature.\n*  Therefore, you perform a so called randomized encouragement trial, where for a random selection of users, a popup appears when opening the app and encourages these users to test new feature. The users who are not randomly selected don’t get a popup message but could also use the new feature.\n*  After a while you collect data on users’ activity and also if they were encouraged and if they used the new feature.\n\n### Load the data and do the following steps: \n\n## Draw a DAG of how you understand the relationships.\n*  NF: New Feature\n*  PU: Pop Up\n*  UC: Unobserved Characteristics\n*  ST: Screen Time\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-1_1d9f6212dc8a04722d5fedad2bf7434c'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(estimatr)\n\n#Load the data\nApp <- readRDS(\"D:/GitHub/cdsba-pamoviedo/Causal_Data_Science_Data/rand_enc.rds\")\n\n# Define DAG\ndag_model <- 'dag {\nbb=\"0,0,1,1\"\nNF [avgpur,pos=\"0.7,0.4\"]\nUC [preavgpur,pos=\"0.8,0.6\"]\nST [card,pos=\"0.9,0.4\"]\nPU [pos=\"0.6,0.4\"]\n\nUC-> NF\nUC -> ST\nNF -> ST\nNF -> PU\n\n\n}\n'\n# draw DAG\nggdag(dag_model) +\n  theme_dag()+\n  geom_dag_point(color = \"blue\") +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"green\")\n```\n\n::: {.cell-output-display}\n![](09_iv_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Compute the naive, biased estimate.\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-2_cfcb722d0a6cf92e0c93493659d21d0f'}\n\n```{.r .cell-code}\n#Compute the naive, biased estimate\nlm_naive <- lm(time_spent ~ used_ftr, data = App)\nsummary(lm_naive)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = time_spent ~ used_ftr, data = App)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 18.86993    0.06955   271.3   <2e-16 ***\n#> used_ftr    10.82269    0.10888    99.4   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 5.351 on 9998 degrees of freedom\n#> Multiple R-squared:  0.497,\tAdjusted R-squared:  0.497 \n#> F-statistic:  9881 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n## For the assumptions that can be (partly) tested, check whether they are satisfied by either computing correlations or drawing plots. Argue whether instrumental variable estimation is an adequate procedure.\n\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-3_c932a300be14e231df6eeb433c97fa71'}\n\n```{.r .cell-code}\n#Correlation computation\ncor_matrix <- cor(App)\nprint(cor_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>             rand_enc  used_ftr time_spent\n#> rand_enc   1.0000000 0.2044110  0.1296716\n#> used_ftr   0.2044110 1.0000000  0.7050147\n#> time_spent 0.1296716 0.7050147  1.0000000\n```\n:::\n\n```{.r .cell-code}\napp_corr <- App %>%\n  filter(used_ftr == 1)\ncor(app_corr$rand_enc,app_corr$time_spent)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] -0.02744462\n```\n:::\n\n```{.r .cell-code}\n#First Stage\nfirst_stage <- lm(used_ftr~time_spent, data = App)\nsummary(first_stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = used_ftr ~ time_spent, data = App)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -1.1469 -0.2593 -0.0247  0.2592  1.1636 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -0.661420   0.011309  -58.48   <2e-16 ***\n#> time_spent   0.045926   0.000462   99.40   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.3486 on 9998 degrees of freedom\n#> Multiple R-squared:  0.497,\tAdjusted R-squared:  0.497 \n#> F-statistic:  9881 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Predicted 'probabilities' from first stage\npred_fs <- predict(first_stage)\n\n# Create table with predictions and actual decisions\npred_vs_actl <- tibble(\n  pred = pred_fs,\n  actl = App$used_ftr\n)\n\n# Plot predictions vs original\nggplot(pred_vs_actl, aes(x = pred, y = actl, color = as.factor(actl))) +\n  geom_jitter(alpha = .5) +\n  scale_color_discrete(labels = c(\"Control Group\", \"Treatment Group\")) +\n  theme(legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](09_iv_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Second stage\nsecond_stage <- lm(App$time_spent ~ first_stage$fitted.values)\nsummary(second_stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = App$time_spent ~ first_stage$fitted.values)\n#> \n#> Residuals:\n#>       Min        1Q    Median        3Q       Max \n#> -8.30e-15 -1.40e-15 -7.00e-16 -1.00e-16  5.58e-12 \n#> \n#> Coefficients:\n#>                            Estimate Std. Error   t value Pr(>|t|)    \n#> (Intercept)               1.440e+01  8.900e-16 1.618e+16   <2e-16 ***\n#> first_stage$fitted.values 2.177e+01  1.663e-15 1.309e+16   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 5.761e-14 on 9998 degrees of freedom\n#> Multiple R-squared:      1,\tAdjusted R-squared:      1 \n#> F-statistic: 1.715e+32 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n*  IV estimation can provide more credible causal estimates if the 5-prerequisites (Stable unit treatment value assumption, Independence assumption, Exclusion restriction, Instrument relevance and Monotonicity assumption) are met. \n\n## Compute the IV estimate using 2SLS and compare it to the naive estimate. Would you consider the naive estimate biased, and if yes, does it have an upward or downward bias?\n\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-4_23a14dcffdbb4aeb44cb57ec7b97977d'}\n\n```{.r .cell-code}\nmodel_iv <- iv_robust(time_spent ~ used_ftr | rand_enc, data = App)\nsummary(model_iv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = App)\n#> \n#> Standard error type:  HC2 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper   DF\n#> (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#> used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#> \n#> Multiple R-squared:  0.4921 ,\tAdjusted R-squared:  0.492 \n#> F-statistic:   331 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-5_72c1dbdbe3d146f16cf316ac914f3bed'}\n\n```{.r .cell-code}\ncoefIV<- coef(model_iv)\nprint(coefIV)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept)    used_ftr \n#>   19.312415    9.738175\n```\n:::\n\n```{.r .cell-code}\ncoefNB<- coef(lm_naive)\nprint(coefNB)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept)    used_ftr \n#>    18.86993    10.82269\n```\n:::\n:::\n\n\n*  The naive estimate is biased if there are unobserved confounders influencing both the treatment assignment and the outcome. The instrumental variable estimate aims to address this bias by using an instrument that is correlated with the treatment but is not directly related to the outcome, except through its effect on the treatment.\n*  Comparing these estimates, it seems that the naive estimate is larger than the IV estimate. If the instrument is valid (i.e., it satisfies the necessary assumptions), the IV estimate is often considered less biased than the naive estimate. Therefore, it is possible that the naive estimate has an upward bias.\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}